{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10_from_softmax_to_transfer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO41WSHAW6RRWf4A0r3y52v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/borislevant/CourseraMachineLearning/blob/master/cifar10_from_softmax_to_transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Introduction.\n",
        "The CIFAR-10 dataset contains 60,000 color images of 32 x 32 pixels in 3 channels divided into 10\n",
        "classes. Each class contains 6,000 images. The training set contains 50,000 images, while the test sets\n",
        "provides 10,000 images. This image taken from the CIFAR repository ( <a href = \"https://www.cs.toronto.edu/~kriz/cifar.html\">https://www.cs.toronto.edu/~kriz/cifar.html </a>). This is a classification problem with 10 classes(muti-label classification). We can take a view on this image for more comprehension of the dataset. \n",
        "\n",
        "![cifar10.png](https://github.com/borislevant/SciComPy/blob/master/cifar10.png?raw=1)\n",
        "\n",
        "\n",
        "The challenge is to recognize previously unseen images and assign them to one of the 10 classes.\n",
        "\n",
        "Ok Let's get started."
      ],
      "metadata": {
        "id": "ODkXzxzJX4RV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Import and Preprocess the data\n",
        "\n",
        "### 2.1 Import all required libraries"
      ],
      "metadata": {
        "id": "8loO1ZCAYNFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from tensorflow import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import itertools\n",
        "\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "RxZygPoMYOJi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32  # The default batch size of keras.\n",
        "num_classes = 10  # Number of class for the dataset\n",
        "epochs = 100\n",
        "data_augmentation = False"
      ],
      "metadata": {
        "id": "Q1nImjQpciHS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.2 Import and preproces of data \n",
        "We load the data and split it between train and test sets\n"
      ],
      "metadata": {
        "id": "od0ht3ORYW_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vQGeMoaYZeP",
        "outputId": "79413d96-9e15-4e47-8283-16d77f444d0a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "y_train shape: (50000, 1)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data. Before we need to connvert data type to float for computation.\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Convert class vectors to binary class matrices. This is called one hot encoding.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "bMdzujJVcfoI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Softmax model"
      ],
      "metadata": {
        "id": "vJ6g0nKpaVf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=x_train.shape[1:]))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHHh5oltaVDa",
        "outputId": "ea7879a4-6d76-4dbf-ed59-498fadf71926"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 3072)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                30730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,730\n",
            "Trainable params: 30,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "zhIS8Otbb_GI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nstz6VYcaBw1",
        "outputId": "7137282b-d1da-4e9c-d12e-edf25020117c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 8s 3ms/step - loss: 1.9842 - accuracy: 0.2909 - val_loss: 1.8764 - val_accuracy: 0.3352\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8517 - accuracy: 0.3517 - val_loss: 1.8213 - val_accuracy: 0.3652\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8168 - accuracy: 0.3671 - val_loss: 1.8104 - val_accuracy: 0.3659\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7963 - accuracy: 0.3738 - val_loss: 1.7912 - val_accuracy: 0.3788\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7825 - accuracy: 0.3801 - val_loss: 1.7921 - val_accuracy: 0.3751\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7712 - accuracy: 0.3884 - val_loss: 1.7746 - val_accuracy: 0.3823\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7625 - accuracy: 0.3912 - val_loss: 1.7859 - val_accuracy: 0.3776\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7548 - accuracy: 0.3950 - val_loss: 1.7662 - val_accuracy: 0.3837\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7484 - accuracy: 0.3994 - val_loss: 1.7774 - val_accuracy: 0.3818\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7429 - accuracy: 0.3996 - val_loss: 1.7577 - val_accuracy: 0.3847\n",
            "Epoch 11/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7386 - accuracy: 0.4030 - val_loss: 1.7658 - val_accuracy: 0.3796\n",
            "Epoch 12/100\n",
            " 324/1563 [=====>........................] - ETA: 3s - loss: 1.7544 - accuracy: 0.3944"
          ]
        }
      ]
    }
  ]
}