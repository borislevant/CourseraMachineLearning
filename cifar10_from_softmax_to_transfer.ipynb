{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10_from_softmax_to_transfer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/borislevant/CourseraMachineLearning/blob/master/cifar10_from_softmax_to_transfer.ipynb",
      "authorship_tag": "ABX9TyMmKPpSx/bC2CuXty3h3MYL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/borislevant/CourseraMachineLearning/blob/master/cifar10_from_softmax_to_transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we will demonstrate the work on the CIFAR-10 data set from the simplest Softmax model (Logistic regression) to the more advanced methods"
      ],
      "metadata": {
        "id": "7dy5Gp7sziul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Introduction\n",
        "The CIFAR-10 dataset contains 60,000 color images of 32 x 32 pixels in 3 channels divided into 10\n",
        "classes. Each class contains 6,000 images. The training set contains 50,000 images, while the test sets\n",
        "provides 10,000 images. This image taken from the CIFAR repository ( <a href = \"https://www.cs.toronto.edu/~kriz/cifar.html\">https://www.cs.toronto.edu/~kriz/cifar.html </a>). This is a classification problem with 10 classes(muti-label classification). We can take a view on this image for more comprehension of the dataset. \n",
        "\n",
        "![cifar10.png](https://github.com/borislevant/SciComPy/blob/master/cifar10.png?raw=1)\n",
        "\n",
        "\n",
        "The challenge is to recognize previously unseen images and assign them to one of the 10 classes.\n",
        "\n",
        "Ok Let's get started."
      ],
      "metadata": {
        "id": "ODkXzxzJX4RV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Import and Preprocess the data\n",
        "\n"
      ],
      "metadata": {
        "id": "8loO1ZCAYNFq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Import all required libraries"
      ],
      "metadata": {
        "id": "CQEVEyzgcsQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from tensorflow import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, InputLayer\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import itertools\n",
        "\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "RxZygPoMYOJi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32  # The default batch size of keras.\n",
        "num_classes = 10  # Number of class for the dataset\n",
        "epochs = 30\n",
        "data_augmentation = False\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "reg = keras.regularizers.l2(l2=0.0001)"
      ],
      "metadata": {
        "id": "Q1nImjQpciHS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Import and preproces of data \n",
        "We load the data and split it between train and test sets\n"
      ],
      "metadata": {
        "id": "od0ht3ORYW_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vQGeMoaYZeP",
        "outputId": "32579e54-6cd8-4f86-ed8a-ae28273f9912"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 13s 0us/step\n",
            "170508288/170498071 [==============================] - 13s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "y_train shape: (50000, 1)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data. Before we need to connvert data type to float for computation.\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Convert class vectors to binary class matrices. This is called one hot encoding.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "bMdzujJVcfoI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Softmax model"
      ],
      "metadata": {
        "id": "vJ6g0nKpaVf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=x_train.shape[1:]))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax', kernel_regularizer=reg))\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHHh5oltaVDa",
        "outputId": "924e5724-ef63-4bdc-ce46-1820b99b42bc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 3072)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                30730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,730\n",
            "Trainable params: 30,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "\n",
        "model.save(r'/content/drive/MyDrive/projects/model_softmax', save_format='h5')\n",
        "pd.DataFrame(history.history).to_csv('/content/drive/MyDrive/projects/history_softmax.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nstz6VYcaBw1",
        "outputId": "99c63dbd-e5ce-48bc-a9e2-59be4229d66a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1563/1563 [==============================] - 8s 3ms/step - loss: 1.9777 - accuracy: 0.2990 - val_loss: 1.8886 - val_accuracy: 0.3317\n",
            "Epoch 2/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.8490 - accuracy: 0.3556 - val_loss: 1.8369 - val_accuracy: 0.3463\n",
            "Epoch 3/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.8153 - accuracy: 0.3705 - val_loss: 1.8171 - val_accuracy: 0.3681\n",
            "Epoch 4/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7950 - accuracy: 0.3794 - val_loss: 1.7877 - val_accuracy: 0.3801\n",
            "Epoch 5/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7793 - accuracy: 0.3838 - val_loss: 1.7905 - val_accuracy: 0.3777\n",
            "Epoch 6/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7698 - accuracy: 0.3905 - val_loss: 1.7745 - val_accuracy: 0.3898\n",
            "Epoch 7/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7623 - accuracy: 0.3939 - val_loss: 1.7657 - val_accuracy: 0.3908\n",
            "Epoch 8/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7540 - accuracy: 0.3956 - val_loss: 1.7542 - val_accuracy: 0.3966\n",
            "Epoch 9/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7473 - accuracy: 0.3975 - val_loss: 1.7682 - val_accuracy: 0.3836\n",
            "Epoch 10/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7399 - accuracy: 0.4046 - val_loss: 1.7568 - val_accuracy: 0.3907\n",
            "Epoch 11/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7371 - accuracy: 0.4042 - val_loss: 1.7449 - val_accuracy: 0.3986\n",
            "Epoch 12/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7320 - accuracy: 0.4069 - val_loss: 1.7556 - val_accuracy: 0.3891\n",
            "Epoch 13/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7285 - accuracy: 0.4097 - val_loss: 1.7514 - val_accuracy: 0.3876\n",
            "Epoch 14/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7266 - accuracy: 0.4090 - val_loss: 1.7415 - val_accuracy: 0.3949\n",
            "Epoch 15/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7225 - accuracy: 0.4114 - val_loss: 1.7452 - val_accuracy: 0.3988\n",
            "Epoch 16/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7188 - accuracy: 0.4135 - val_loss: 1.7390 - val_accuracy: 0.3992\n",
            "Epoch 17/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7171 - accuracy: 0.4121 - val_loss: 1.7401 - val_accuracy: 0.4002\n",
            "Epoch 18/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7145 - accuracy: 0.4131 - val_loss: 1.7397 - val_accuracy: 0.3927\n",
            "Epoch 19/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7116 - accuracy: 0.4141 - val_loss: 1.7625 - val_accuracy: 0.3863\n",
            "Epoch 20/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7107 - accuracy: 0.4150 - val_loss: 1.7560 - val_accuracy: 0.3901\n",
            "Epoch 21/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7069 - accuracy: 0.4182 - val_loss: 1.7451 - val_accuracy: 0.3916\n",
            "Epoch 22/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7050 - accuracy: 0.4176 - val_loss: 1.7504 - val_accuracy: 0.3925\n",
            "Epoch 23/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7047 - accuracy: 0.4184 - val_loss: 1.7351 - val_accuracy: 0.3989\n",
            "Epoch 24/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7014 - accuracy: 0.4182 - val_loss: 1.7286 - val_accuracy: 0.3988\n",
            "Epoch 25/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6996 - accuracy: 0.4204 - val_loss: 1.7332 - val_accuracy: 0.4002\n",
            "Epoch 26/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6994 - accuracy: 0.4210 - val_loss: 1.7294 - val_accuracy: 0.4002\n",
            "Epoch 27/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6979 - accuracy: 0.4208 - val_loss: 1.7390 - val_accuracy: 0.3925\n",
            "Epoch 28/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6966 - accuracy: 0.4229 - val_loss: 1.7246 - val_accuracy: 0.4052\n",
            "Epoch 29/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6944 - accuracy: 0.4219 - val_loss: 1.7297 - val_accuracy: 0.4059\n",
            "Epoch 30/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6925 - accuracy: 0.4232 - val_loss: 1.7317 - val_accuracy: 0.4006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Fully-connected Neural Network (FNN) model"
      ],
      "metadata": {
        "id": "NNNPoEFCfWZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=x_train.shape[1:]))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu', kernel_regularizer=reg))\n",
        "model.add(Dense(256, activation='relu', kernel_regularizer=reg))\n",
        "model.add(Dense(64, activation='relu', kernel_regularizer=reg))\n",
        "model.add(Dense(num_classes, activation='softmax', kernel_regularizer=reg))\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ6jPs0FfV_-",
        "outputId": "fb04035a-0de2-47c1-848c-0fc348e08809"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1024)              3146752   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               262400    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,426,250\n",
            "Trainable params: 3,426,250\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "\n",
        "model.save(r'/content/drive/MyDrive/projects/model_fnn', save_format='h5')\n",
        "pd.DataFrame(history.history).to_csv('/content/drive/MyDrive/projects/history_fnn.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v44TLZmOftmC",
        "outputId": "a8e01e53-e658-4b31-ad6f-a0b2540fbc9c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.9790 - accuracy: 0.3381 - val_loss: 1.7979 - val_accuracy: 0.3974\n",
            "Epoch 2/30\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.7534 - accuracy: 0.4076 - val_loss: 1.6873 - val_accuracy: 0.4346\n",
            "Epoch 3/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.6597 - accuracy: 0.4366 - val_loss: 1.6427 - val_accuracy: 0.4386\n",
            "Epoch 4/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5939 - accuracy: 0.4563 - val_loss: 1.5857 - val_accuracy: 0.4586\n",
            "Epoch 5/30\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5461 - accuracy: 0.4705 - val_loss: 1.5381 - val_accuracy: 0.4798\n",
            "Epoch 6/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5097 - accuracy: 0.4845 - val_loss: 1.5385 - val_accuracy: 0.4783\n",
            "Epoch 7/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.4797 - accuracy: 0.4933 - val_loss: 1.5212 - val_accuracy: 0.4808\n",
            "Epoch 8/30\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4502 - accuracy: 0.5050 - val_loss: 1.5270 - val_accuracy: 0.4794\n",
            "Epoch 9/30\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.4251 - accuracy: 0.5172 - val_loss: 1.4747 - val_accuracy: 0.4960\n",
            "Epoch 10/30\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3984 - accuracy: 0.5255 - val_loss: 1.4734 - val_accuracy: 0.5002\n",
            "Epoch 11/30\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.3780 - accuracy: 0.5336 - val_loss: 1.4565 - val_accuracy: 0.5050\n",
            "Epoch 12/30\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.3563 - accuracy: 0.5416 - val_loss: 1.4367 - val_accuracy: 0.5112\n",
            "Epoch 13/30\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3340 - accuracy: 0.5489 - val_loss: 1.4388 - val_accuracy: 0.5115\n",
            "Epoch 14/30\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.3149 - accuracy: 0.5583 - val_loss: 1.4107 - val_accuracy: 0.5247\n",
            "Epoch 15/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2970 - accuracy: 0.5655 - val_loss: 1.4165 - val_accuracy: 0.5245\n",
            "Epoch 16/30\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2792 - accuracy: 0.5744 - val_loss: 1.4002 - val_accuracy: 0.5313\n",
            "Epoch 17/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2597 - accuracy: 0.5812 - val_loss: 1.4394 - val_accuracy: 0.5141\n",
            "Epoch 18/30\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2450 - accuracy: 0.5854 - val_loss: 1.4210 - val_accuracy: 0.5232\n",
            "Epoch 19/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2303 - accuracy: 0.5902 - val_loss: 1.3979 - val_accuracy: 0.5358\n",
            "Epoch 20/30\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2157 - accuracy: 0.5959 - val_loss: 1.3888 - val_accuracy: 0.5363\n",
            "Epoch 21/30\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.1955 - accuracy: 0.6044 - val_loss: 1.3938 - val_accuracy: 0.5348\n",
            "Epoch 22/30\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.1821 - accuracy: 0.6066 - val_loss: 1.4032 - val_accuracy: 0.5286\n",
            "Epoch 23/30\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1668 - accuracy: 0.6148 - val_loss: 1.3918 - val_accuracy: 0.5420\n",
            "Epoch 24/30\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1527 - accuracy: 0.6202 - val_loss: 1.3919 - val_accuracy: 0.5415\n",
            "Epoch 25/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.1392 - accuracy: 0.6234 - val_loss: 1.4118 - val_accuracy: 0.5306\n",
            "Epoch 26/30\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.1245 - accuracy: 0.6309 - val_loss: 1.3809 - val_accuracy: 0.5458\n",
            "Epoch 27/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.1104 - accuracy: 0.6364 - val_loss: 1.3913 - val_accuracy: 0.5402\n",
            "Epoch 28/30\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0985 - accuracy: 0.6401 - val_loss: 1.3624 - val_accuracy: 0.5536\n",
            "Epoch 29/30\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0842 - accuracy: 0.6465 - val_loss: 1.3960 - val_accuracy: 0.5426\n",
            "Epoch 30/30\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0715 - accuracy: 0.6512 - val_loss: 1.3768 - val_accuracy: 0.5473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Convolutional Neural Network"
      ],
      "metadata": {
        "id": "vd2oGltPMKq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define the convnet\n",
        "model = Sequential()\n",
        "# CONV => RELU => CONV => RELU => POOL => DROPOUT\n",
        "model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# CONV => RELU => CONV => RELU => POOL => DROPOUT\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# FLATTERN => DENSE => RELU => DROPOUT\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "# a softmax classifier\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8znMBMaGNNss",
        "outputId": "8e09b234-a8c4-497f-fc41-30f6f5ad0ee9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 30, 30, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 15, 15, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 15, 15, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 13, 13, 64)        36928     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 13, 13, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 6, 6, 64)          0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 2304)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 512)               1180160   \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "\n",
        "model.save(r'/content/drive/MyDrive/projects/model_cnn', save_format='h5')\n",
        "pd.DataFrame(history.history).to_csv('/content/drive/MyDrive/projects/history_cnn.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnLQEK30PBAw",
        "outputId": "ae85a46a-ce37-4085-c159-c007bab4a99d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1563/1563 [==============================] - 18s 6ms/step - loss: 1.6483 - accuracy: 0.3976 - val_loss: 1.3792 - val_accuracy: 0.5011\n",
            "Epoch 2/30\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.3807 - accuracy: 0.5019 - val_loss: 1.2451 - val_accuracy: 0.5590\n",
            "Epoch 3/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2674 - accuracy: 0.5487 - val_loss: 1.1484 - val_accuracy: 0.5870\n",
            "Epoch 4/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1862 - accuracy: 0.5812 - val_loss: 1.1117 - val_accuracy: 0.6027\n",
            "Epoch 5/30\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1223 - accuracy: 0.6021 - val_loss: 1.0650 - val_accuracy: 0.6240\n",
            "Epoch 6/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0699 - accuracy: 0.6220 - val_loss: 0.9800 - val_accuracy: 0.6575\n",
            "Epoch 7/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0218 - accuracy: 0.6403 - val_loss: 0.9388 - val_accuracy: 0.6676\n",
            "Epoch 8/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9785 - accuracy: 0.6571 - val_loss: 0.9158 - val_accuracy: 0.6818\n",
            "Epoch 9/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9409 - accuracy: 0.6693 - val_loss: 0.8666 - val_accuracy: 0.6986\n",
            "Epoch 10/30\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8993 - accuracy: 0.6840 - val_loss: 0.8636 - val_accuracy: 0.7005\n",
            "Epoch 11/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8688 - accuracy: 0.6983 - val_loss: 0.8201 - val_accuracy: 0.7136\n",
            "Epoch 12/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8402 - accuracy: 0.7076 - val_loss: 0.8047 - val_accuracy: 0.7257\n",
            "Epoch 13/30\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8136 - accuracy: 0.7158 - val_loss: 0.7904 - val_accuracy: 0.7238\n",
            "Epoch 14/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7859 - accuracy: 0.7270 - val_loss: 0.7524 - val_accuracy: 0.7412\n",
            "Epoch 15/30\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.7610 - accuracy: 0.7323 - val_loss: 0.7466 - val_accuracy: 0.7433\n",
            "Epoch 16/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7358 - accuracy: 0.7444 - val_loss: 0.7293 - val_accuracy: 0.7486\n",
            "Epoch 17/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.7142 - accuracy: 0.7531 - val_loss: 0.7171 - val_accuracy: 0.7531\n",
            "Epoch 18/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6998 - accuracy: 0.7551 - val_loss: 0.7037 - val_accuracy: 0.7587\n",
            "Epoch 19/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6785 - accuracy: 0.7615 - val_loss: 0.6894 - val_accuracy: 0.7602\n",
            "Epoch 20/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6610 - accuracy: 0.7677 - val_loss: 0.6766 - val_accuracy: 0.7646\n",
            "Epoch 21/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6433 - accuracy: 0.7769 - val_loss: 0.7092 - val_accuracy: 0.7548\n",
            "Epoch 22/30\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6206 - accuracy: 0.7811 - val_loss: 0.6870 - val_accuracy: 0.7635\n",
            "Epoch 23/30\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6099 - accuracy: 0.7864 - val_loss: 0.6659 - val_accuracy: 0.7709\n",
            "Epoch 24/30\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5899 - accuracy: 0.7917 - val_loss: 0.6618 - val_accuracy: 0.7736\n",
            "Epoch 25/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5771 - accuracy: 0.7978 - val_loss: 0.6520 - val_accuracy: 0.7753\n",
            "Epoch 26/30\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5624 - accuracy: 0.8009 - val_loss: 0.6483 - val_accuracy: 0.7788\n",
            "Epoch 27/30\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5433 - accuracy: 0.8084 - val_loss: 0.6466 - val_accuracy: 0.7791\n",
            "Epoch 28/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5369 - accuracy: 0.8126 - val_loss: 0.6539 - val_accuracy: 0.7768\n",
            "Epoch 29/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5250 - accuracy: 0.8179 - val_loss: 0.6258 - val_accuracy: 0.7840\n",
            "Epoch 30/30\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5101 - accuracy: 0.8204 - val_loss: 0.6255 - val_accuracy: 0.7853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Transfer learning\n"
      ],
      "metadata": {
        "id": "I3w8UctjMAQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n"
      ],
      "metadata": {
        "id": "AVDQG_axMeLW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(name, weights='imagenet', cut_at=-1, unfreeze_from=0, opt='adam'):\n",
        "    \n",
        "    # load model\n",
        "    model = VGG16(weights=weights, include_top=False, input_shape=(32,32,3))\n",
        "    \n",
        "    # freeze all layer\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    # select layer output\n",
        "    if cut_at==-1:\n",
        "        x = model.output\n",
        "    else:\n",
        "        x = model.layers[cut_at].output\n",
        "        \n",
        "    # add new classifier head\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "    # instantiate new model\n",
        "    myModel = keras.Model(inputs=model.input, outputs=predictions, name=name)\n",
        "        \n",
        "    # unfreeze selected layer\n",
        "    for layer in myModel.layers[unfreeze_from:]:\n",
        "        layer.trainable = True\n",
        "          \n",
        "    # compile model\n",
        "    myModel.compile(\n",
        "          loss='categorical_crossentropy',\n",
        "          optimizer=opt, \n",
        "          metrics=['accuracy']\n",
        "    )\n",
        "          \n",
        "    # print parameters\n",
        "    myModel.summary()\n",
        "    \n",
        "    return myModel"
      ],
      "metadata": {
        "id": "miORxNelR3bj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model = build_model('full_scratch', weights=None)\n",
        "model = build_model('full_scratch', weights='imagenet', unfreeze_from=19)\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "\n",
        "model.save(r'/content/drive/MyDrive/projects/model_vgg_imagenet', save_format='h5')\n",
        "pd.DataFrame(history.history).to_csv('/content/drive/MyDrive/projects/history_vgg_imagenet.csv')\n"
      ],
      "metadata": {
        "id": "i1Lyx4sOR4eh",
        "outputId": "38a482ea-9f6b-45b7-9e5f-806e1ebec6bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"full_scratch\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d_4   (None, 512)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,245,130\n",
            "Trainable params: 530,442\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "1563/1563 [==============================] - 20s 12ms/step - loss: 1.3261 - accuracy: 0.5323 - val_loss: 1.2219 - val_accuracy: 0.5676\n",
            "Epoch 2/30\n",
            "1563/1563 [==============================] - 21s 14ms/step - loss: 1.1417 - accuracy: 0.5989 - val_loss: 1.1802 - val_accuracy: 0.5808\n",
            "Epoch 3/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 1.0638 - accuracy: 0.6243 - val_loss: 1.1515 - val_accuracy: 0.5937\n",
            "Epoch 4/30\n",
            "1563/1563 [==============================] - 21s 14ms/step - loss: 1.0010 - accuracy: 0.6470 - val_loss: 1.1248 - val_accuracy: 0.6094\n",
            "Epoch 5/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.9406 - accuracy: 0.6679 - val_loss: 1.1249 - val_accuracy: 0.6158\n",
            "Epoch 6/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.8812 - accuracy: 0.6871 - val_loss: 1.1370 - val_accuracy: 0.6192\n",
            "Epoch 7/30\n",
            "1563/1563 [==============================] - 21s 14ms/step - loss: 0.8223 - accuracy: 0.7070 - val_loss: 1.1509 - val_accuracy: 0.6111\n",
            "Epoch 8/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.7644 - accuracy: 0.7281 - val_loss: 1.2240 - val_accuracy: 0.6058\n",
            "Epoch 9/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.7107 - accuracy: 0.7439 - val_loss: 1.2608 - val_accuracy: 0.6073\n",
            "Epoch 10/30\n",
            "1563/1563 [==============================] - 21s 14ms/step - loss: 0.6505 - accuracy: 0.7658 - val_loss: 1.2714 - val_accuracy: 0.6105\n",
            "Epoch 11/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.5943 - accuracy: 0.7851 - val_loss: 1.3351 - val_accuracy: 0.6089\n",
            "Epoch 12/30\n",
            "1563/1563 [==============================] - 21s 14ms/step - loss: 0.5381 - accuracy: 0.8066 - val_loss: 1.4278 - val_accuracy: 0.5966\n",
            "Epoch 13/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.4854 - accuracy: 0.8244 - val_loss: 1.5443 - val_accuracy: 0.6040\n",
            "Epoch 14/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.4391 - accuracy: 0.8431 - val_loss: 1.6183 - val_accuracy: 0.5966\n",
            "Epoch 15/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.3930 - accuracy: 0.8586 - val_loss: 1.6860 - val_accuracy: 0.6043\n",
            "Epoch 16/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.3530 - accuracy: 0.8740 - val_loss: 1.8209 - val_accuracy: 0.5979\n",
            "Epoch 17/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.3135 - accuracy: 0.8870 - val_loss: 1.8439 - val_accuracy: 0.6024\n",
            "Epoch 18/30\n",
            "1563/1563 [==============================] - 21s 14ms/step - loss: 0.2862 - accuracy: 0.8971 - val_loss: 1.9970 - val_accuracy: 0.5991\n",
            "Epoch 19/30\n",
            "1563/1563 [==============================] - 22s 14ms/step - loss: 0.2544 - accuracy: 0.9088 - val_loss: 2.1159 - val_accuracy: 0.6005\n",
            "Epoch 20/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.2369 - accuracy: 0.9167 - val_loss: 2.1298 - val_accuracy: 0.6003\n",
            "Epoch 21/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.2106 - accuracy: 0.9244 - val_loss: 2.2702 - val_accuracy: 0.5980\n",
            "Epoch 22/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.1925 - accuracy: 0.9310 - val_loss: 2.4546 - val_accuracy: 0.6041\n",
            "Epoch 23/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.1754 - accuracy: 0.9384 - val_loss: 2.5156 - val_accuracy: 0.6019\n",
            "Epoch 24/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.1669 - accuracy: 0.9414 - val_loss: 2.5500 - val_accuracy: 0.5970\n",
            "Epoch 25/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.1627 - accuracy: 0.9428 - val_loss: 2.6161 - val_accuracy: 0.5909\n",
            "Epoch 26/30\n",
            "1563/1563 [==============================] - 21s 14ms/step - loss: 0.1426 - accuracy: 0.9500 - val_loss: 2.7940 - val_accuracy: 0.6000\n",
            "Epoch 27/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.1370 - accuracy: 0.9522 - val_loss: 2.9305 - val_accuracy: 0.5999\n",
            "Epoch 28/30\n",
            "1563/1563 [==============================] - 22s 14ms/step - loss: 0.1336 - accuracy: 0.9526 - val_loss: 3.0275 - val_accuracy: 0.5951\n",
            "Epoch 29/30\n",
            "1563/1563 [==============================] - 21s 14ms/step - loss: 0.1273 - accuracy: 0.9550 - val_loss: 2.9922 - val_accuracy: 0.5952\n",
            "Epoch 30/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.1241 - accuracy: 0.9558 - val_loss: 3.0707 - val_accuracy: 0.5887\n"
          ]
        }
      ]
    }
  ]
}